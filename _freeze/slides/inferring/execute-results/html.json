{
  "hash": "2cc9c236a606c8818d9fedc5ba0946b0",
  "result": {
    "markdown": "---\ntitle: Inferring\nlang: en\nsubtitle: Prompt Engineering 4\nauthor: Jan Kirenz\nexecute:\n  eval: true\n  echo: true\nhighlight-style: github\nformat:\n  revealjs: \n    toc: true\n    toc-depth: 2\n    embed-resources: false\n    theme: [dark, ../custom.scss]  \n    incremental: false\n    transition: slide\n    background-transition: fade\n    transition-speed: slow\n    code-copy: true\n    code-line-numbers: true\n    smaller: true\n    scrollable: true\n    slide-number: c\n    preview-links: auto\n    chalkboard: \n      buttons: false\n   #logo: images/logo.png\n    footer: Jan Kirenz\n---\n\n# Setup\n\n## API key and Python libaries\n\n::: {#e962ebd8 .cell execution_count=1}\n``` {.python .cell-code}\nimport openai\nimport os\n\nfrom dotenv import load_dotenv, find_dotenv\n_ = load_dotenv(find_dotenv())  # read local .env file\n\nopenai.api_key = os.getenv('OPENAI_API_KEY')\n```\n:::\n\n\n## Helper function {.smaller}\n\n::: {#4c731875 .cell execution_count=2}\n``` {.python .cell-code}\ndef get_completion(prompt, model=\"gpt-3.5-turbo\"):\n    messages = [{\"role\": \"user\", \"content\": prompt}]\n    response = openai.ChatCompletion.create(\n        model=model,\n        messages=messages,\n        temperature=0,  # this is the degree of randomness of the model's output\n    )\n    return response.choices[0].message[\"content\"]\n\n```\n:::\n\n\n# Product review example\n\n## Text\n\n::: {#1b1940ae .cell execution_count=3}\n``` {.python .cell-code}\nlamp_review = \"\"\"\nNeeded a nice lamp for my bedroom, and this one had \\\nadditional storage and not too high of a price point. \\\nGot it fast.  The string to our lamp broke during the \\\ntransit and the company happily sent over a new one. \\\nCame within a few days as well. It was easy to put \\\ntogether.  I had a missing part, so I contacted their \\\nsupport and they very quickly got me the missing piece! \\\nLumina seems to me to be a great company that cares \\\nabout their customers and products!!\n\"\"\"\n```\n:::\n\n\n## Infer sentiment \n\n::: {#c04656ad .cell output-location='slide' execution_count=4}\n``` {.python .cell-code}\nprompt = f\"\"\"\nWhat is the sentiment of the following product review, \nwhich is delimited with triple backticks?\n\nReview text: '''{lamp_review}'''\n\"\"\"\nresponse = get_completion(prompt)\nprint(response)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nThe sentiment of the product review is positive.\n```\n:::\n:::\n\n\n## Infer sentiment (positive/negative)\n\n::: {#e45e4b4f .cell output-location='slide' execution_count=5}\n``` {.python .cell-code}\nprompt = f\"\"\"\nWhat is the sentiment of the following product review, \nwhich is delimited with triple backticks?\n\nGive your answer as a single word, either \"positive\" \\\nor \"negative\".\n\nReview text: '''{lamp_review}'''\n\"\"\"\nresponse = get_completion(prompt)\nprint(response)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\npositive\n```\n:::\n:::\n\n\n## Identify types of emotions\n\n::: {#03ff36ff .cell output-location='slide' execution_count=6}\n``` {.python .cell-code}\nprompt = f\"\"\"\nIdentify a list of emotions that the writer of the \\\nfollowing review is expressing. Include no more than \\\nfive items in the list. Format your answer as a list of \\\nlower-case words separated by commas.\n\nReview text: '''{lamp_review}'''\n\"\"\"\nresponse = get_completion(prompt)\nprint(response)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nsatisfied, grateful, impressed, pleased, happy\n```\n:::\n:::\n\n\n## Identify anger\n\n::: {#91f7a8f0 .cell output-location='slide' execution_count=7}\n``` {.python .cell-code}\nprompt = f\"\"\"\nIs the writer of the following review expressing anger?\\\nThe review is delimited with triple backticks. \\\nGive your answer as either yes or no.\n\nReview text: '''{lamp_review}'''\n\"\"\"\nresponse = get_completion(prompt)\nprint(response)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nNo\n```\n:::\n:::\n\n\n## Extract product and company name\n\n::: {#878cdcea .cell output-location='slide' execution_count=8}\n``` {.python .cell-code}\nprompt = f\"\"\"\nIdentify the following items from the review text: \n- Item purchased by reviewer\n- Company that made the item\n\nThe review is delimited with triple backticks. \\\nFormat your response as a JSON object with \\\n\"Item\" and \"Brand\" as the keys. \nIf the information isn't present, use \"unknown\" \\\nas the value.\nMake your response as short as possible.\n  \nReview text: '''{lamp_review}'''\n\"\"\"\nresponse = get_completion(prompt)\nprint(response)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n{\n  \"Item\": \"lamp\",\n  \"Brand\": \"Lumina\"\n}\n```\n:::\n:::\n\n\n## Doing multiple tasks at once\n\n::: {#b73ebead .cell output-location='slide' execution_count=9}\n``` {.python .cell-code}\nprompt = f\"\"\"\nIdentify the following items from the review text: \n- Sentiment (positive or negative)\n- Is the reviewer expressing anger? (true or false)\n- Item purchased by reviewer\n- Company that made the item\n\nThe review is delimited with triple backticks. \\\nFormat your response as a JSON object with \\\n\"Sentiment\", \"Anger\", \"Item\" and \"Brand\" as the keys.\nIf the information isn't present, use \"unknown\" \\\nas the value.\nMake your response as short as possible.\nFormat the Anger value as a boolean.\n\nReview text: '''{lamp_review}'''\n\"\"\"\nresponse = get_completion(prompt)\nprint(response)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n{\n  \"Sentiment\": \"positive\",\n  \"Anger\": false,\n  \"Item\": \"lamp\",\n  \"Brand\": \"Lumina\"\n}\n```\n:::\n:::\n\n\n# Inferring topics\n\n## Text\n\n::: {#ac4e04fa .cell execution_count=10}\n``` {.python .cell-code}\nstory = \"\"\"\nIn a recent survey conducted by the government, \npublic sector employees were asked to rate their level \nof satisfaction with the department they work at. \nThe results revealed that NASA was the most popular \ndepartment with a satisfaction rating of 95%.\n\nOne NASA employee, John Smith, commented on the findings, \nstating, \"I'm not surprised that NASA came out on top. \nIt's a great place to work with amazing people and \nincredible opportunities. I'm proud to be a part of \nsuch an innovative organization.\"\n\nThe results were also welcomed by NASA's management team, \nwith Director Tom Johnson stating, \"We are thrilled to \nhear that our employees are satisfied with their work at NASA. \nWe have a talented and dedicated team who work tirelessly \nto achieve our goals, and it's fantastic to see that their \nhard work is paying off.\"\n\nThe survey also revealed that the \nSocial Security Administration had the lowest satisfaction \nrating, with only 45% of employees indicating they were \nsatisfied with their job. The government has pledged to \naddress the concerns raised by employees in the survey and \nwork towards improving job satisfaction across all departments.\n\"\"\"\n```\n:::\n\n\n## Infer 5 topics\n\n::: {#7f406f97 .cell output-location='slide' execution_count=11}\n``` {.python .cell-code}\nprompt = f\"\"\"\nDetermine five topics that are being discussed in the \\\nfollowing text, which is delimited by triple backticks.\n\nMake each item one or two words long. \n\nFormat your response as a list of items separated by commas.\n\nText sample: '''{story}'''\n\"\"\"\nresponse = get_completion(prompt)\nprint(response)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n1. Government survey\n2. Department satisfaction rating\n3. NASA\n4. Social Security Administration\n5. Job satisfaction improvement\n```\n:::\n:::\n\n\n## Split responses\n\n::: {#ed652d65 .cell execution_count=12}\n``` {.python .cell-code}\nresponse.split(sep=',')\n```\n\n::: {.cell-output .cell-output-display execution_count=12}\n```\n['1. Government survey\\n2. Department satisfaction rating\\n3. NASA\\n4. Social Security Administration\\n5. Job satisfaction improvement']\n```\n:::\n:::\n\n\n## Topic list \n\n::: {#c4cd7dec .cell execution_count=13}\n``` {.python .cell-code}\ntopic_list = [\n    \"nasa\", \"local government\", \"engineering\",\n    \"employee satisfaction\", \"federal government\"\n]\n```\n:::\n\n\n## Give answer as list with 0 and 1\n\n::: {#6cbc2d1e .cell output-location='slide' execution_count=14}\n``` {.python .cell-code}\nprompt = f\"\"\"\nDetermine whether each item in the following list of \\\ntopics is a topic in the text below, which\nis delimited with triple backticks.\n\nGive your answer as list with 0 or 1 for each topic.\\\n\nList of topics: {\", \".join(topic_list)}\n\nText sample: '''{story}'''\n\"\"\"\nresponse = get_completion(prompt)\nprint(response)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1, 0, 0, 1, 1]\n```\n:::\n:::\n\n\n",
    "supporting": [
      "inferring_files"
    ],
    "filters": [],
    "includes": {}
  }
}