{
  "hash": "2a13269ef7de4c9a0883d892bf487909",
  "result": {
    "markdown": "---\ntitle: Prompt Engineering Guidelines\nlang: en\nsubtitle: Prompt Engineering 1\nauthor: Jan Kirenz\nexecute:\n  eval: false\n  echo: true\nhighlight-style: github\nformat:\n  revealjs: \n    toc: true\n    toc-depth: 1\n    embed-resources: false\n    theme: [dark, ../custom.scss]  \n    incremental: true\n    transition: slide\n    background-transition: fade\n    transition-speed: slow\n    code-copy: true\n    code-line-numbers: true\n    smaller: false\n    scrollable: true\n    slide-number: c\n    preview-links: auto\n    chalkboard: \n      buttons: false\n   #logo: images/logo.png\n    footer: Jan Kirenz\n---\n\n# Introduction\n\n## What is prompt engineering?\n\n- The inputs to LLMs are referred to as \"**prompts**\"\n\n- Designing a prompt is essentially how you “program” a LLM:\n  - with **instructions** \n  - or some **examples** of how to successfully complete a task\n\n- Prompt **engineering**\n  - methods to improve model reasoning \n  - reduce the likelihood of model hallucinations\n\n\n## Prompting in ChatGPT\n\n![](/images/prompt.png)\n\n## We use OpenAI's API {.smaller}\n\n![](/images/api.png)\n\n\n- The OpenAI API can be applied to virtually any task that requires understanding or generating natural language and code. \n\n- Can also be used to generate and edit images or convert speech into text.\n\n## Example prompt {.smaller}\n\n- Example prompt with a *system message* (helps set the behavior of the assistant)\n\n. . .\n\n::: {.cell execution_count=1}\n```` {.python .cell-code}\nprompt = f\"\"\"\nSummarize the text delimited by triple backticks \\ \ninto a single sentence and add a joke or playful comment\n\n```{text}```\n\"\"\"\n````\n:::\n\n\n- `f`: [Formatted strings](https://docs.python.org/3/tutorial/inputoutput.html) allow you to embed expressions inside string literals, using curly braces {}\n- `\"\"\"`: Triple double-quotes are used to denote a string that spans multiple lines. \n- `\\`: line breaks are used to make the text more readable\n- `{text}` is a placeholder for a variable text that will be placed into the string at that position. \n\n## Example text\n\n::: {.cell execution_count=2}\n``` {.python .cell-code}\ntext = f\"\"\"\nYou should express what you want a model to do by \\ \nproviding instructions that are as clear and \\ \nspecific as you can possibly make them. \\ \nThis will guide the model towards the desired output, \\ \nand reduce the chances of receiving irrelevant \\ \nor incorrect responses. Don't confuse writing a \\ \nclear prompt with writing a short prompt. \\ \nIn many cases, longer prompts provide more clarity \\ \nand context for the model, which can lead to \\ \nmore detailed and relevant outputs.\n\"\"\"\n```\n:::\n\n\n## Chat completion helper function {.smaller}\n\n::: {.cell execution_count=3}\n``` {.python .cell-code}\ndef get_completion(prompt, model=\"gpt-3.5-turbo\"): # <1>\n    messages = [{\"role\": \"user\", \"content\": prompt}] # <2>\n    response = openai.ChatCompletion.create( # <3>\n        model=model, # <4>\n        messages=messages, # <5>\n        temperature=0)   # <6>  \n    return response.choices[0].message[\"content\"] # <7>\n```\n:::\n\n\n1. Defines a new function named `get_completion` with two parameters: `prompt` and `model`\n2. Dictionary with two key-value pairs: setting the role as `\"user\"` and content as the `prompt` received by the function.\n3. Initiates an API call to OpenAI's [ChatCompletion](https://platform.openai.com/docs/guides/chat) method, the result of which is stored in a variable named `response`.\n4. Specifies the language model to be used for the completion (for cost efficiency reasons we always use `\"gpt-3.5-turbo\"`) \n5. Passes the `messages` list constructed earlier to the API (will be used as the conversation history)\n6. The degree of randomness of the model's output (0 makes the model's output more focused and deterministic).\n7. Extracts and returns the content of the message from the first choice in the `choices` array present in the `response` object. \n\n\n## What is a sytem message?\n\n- The *system message* is optional and helps set the behavior of the assistant.\n\n- You can modify the *personality* of the assistant or provide *specific instructions* about how it should behave\n  - If outputs are too simple, ask for expert-level writing.  \n  - If you dislike the format, demonstrate the format you’d like to see. \n  - You can also use specific personas (e.g. write in the style of Socrates)\n\n## What is the temperature?\n\n- Lower values for temperature result in more consistent outputs\n\n- Higher values generate more diverse and creative results. \n\n- Select a temperature value based on the desired trade-off between coherence and creativity for your specific application.\n\n\n## What are tokens?\n\n- Language models read and write text in chunks called tokens. \n\n- In English, a token can be as short as one character or as long as one word (e.g., a or apple), \n\n- For example, the string \"ChatGPT is great!\" is encoded into six tokens: \n  - `[\"Chat\", \"G\", \"PT\", \" is\", \" great\", \"!\"]`.\n\n## Tokens and API calls\n\n- The total number of tokens in an API call affects:\n  - How much your API call costs, as you pay per token\n  - How long your API call takes, as writing more tokens takes more time\n  - Whether your API call works at all, as total tokens must be below the model’s maximum limit (4097 tokens for gpt-3.5-turbo)\n\n<!--\n\n## Function calling {.smaller}\n\n- Function calling allows you to more reliably get structured data back from the model\n\n- Examples: \n\n  - Create chatbots that answer questions by calling external APIs (e.g. like ChatGPT Plugins): e.g. define functions like send_email(to: string, body: string), or get_current_weather(location: string, unit: 'celsius' | 'fahrenheit')\n\n  - Convert natural language into API calls: e.g. convert \"Who are my top customers?\" to get_customers(min_revenue: int, created_before: string, limit: int) and call your internal API\n\n  - Extract structured data from text: e.g. define a function called extract_data(name: string, birthday: string), or sql_query(query: string)\n-->\n\n# Setup\n\n## API key and Python libaries\n\n::: {.cell execution_count=4}\n``` {.python .cell-code}\nimport openai\nimport os\n\nfrom dotenv import load_dotenv, find_dotenv\n_ = load_dotenv(find_dotenv())\n\nopenai.api_key = os.getenv('OPENAI_API_KEY')\n```\n:::\n\n\n## Helper function {.smaller}\n\n::: {.cell execution_count=5}\n``` {.python .cell-code}\ndef get_completion(prompt, model=\"gpt-3.5-turbo\"):\n    messages = [{\"role\": \"user\", \"content\": prompt}]\n    response = openai.ChatCompletion.create(\n        model=model,\n        messages=messages,\n        temperature=0, \n    )\n    return response.choices[0].message[\"content\"]\n\n```\n:::\n\n\n# Prompting Principle 1\n\nWrite clear and specific instructions\n\n\n## Use delimiters {.smaller}\n\n- Always use delimiters (like backticks) to clearly indicate distinct parts of the input\n\n. . .\n\n::: {.cell output-location='fragment' execution_count=6}\n```` {.python .cell-code}\ntext = f\"\"\"\nYou should express what you want a model to do by \\ \nproviding instructions that are as clear and \\ \nspecific as you can possibly make them. \\ \nThis will guide the model towards the desired output, \\ \nand reduce the chances of receiving irrelevant \\ \nor incorrect responses. Don't confuse writing a \\ \nclear prompt with writing a short prompt. \\ \nIn many cases, longer prompts provide more clarity \\ \nand context for the model, which can lead to \\ \nmore detailed and relevant outputs.\n\"\"\"\nprompt = f\"\"\"\nSummarize the text delimited by triple backticks \\ \ninto a single sentence and add a joke or playful comment\n```{text}```\n\"\"\"\nresponse = get_completion(prompt)\nprint(response)\n````\n:::\n\n\n- *Output:* \"To get the desired output from a model, it's important to give clear and specific instructions, and remember that longer prompts can actually be more helpful in providing context and clarity—just like how a detailed joke is often funnier!\"\n\n\n\n## Ask for structured output {.smaller}\n\n- Ask for a structured output (e.g. JSON, HTML, ...)\n\n. . .\n\n::: {.cell execution_count=7}\n``` {.python .cell-code}\nprompt = f\"\"\"\nGenerate a list of three made-up book titles along \\ \nwith their authors and genres. \nProvide them in JSON format with the following keys: \nbook_id, title, author, genre.\n\"\"\"\n```\n:::\n\n\n. . .\n\n::: {.cell execution_count=8}\n``` {.python .cell-code}\nresponse = get_completion(prompt)\nprint(response)\n```\n:::\n\n\n## Output {.smaller}\n\n```json\n{\n  \"books\": [\n    {\n      \"book_id\": 1,\n      \"title\": \"The Enigma of Elysium\",\n      \"author\": \"Evelyn Sinclair\",\n      \"genre\": \"Mystery\"\n    },\n    {\n      \"book_id\": 2,\n      \"title\": \"Whispers in the Wind\",\n      \"author\": \"Nathaniel Blackwood\",\n      \"genre\": \"Fantasy\"\n    },\n    {\n      \"book_id\": 3,\n      \"title\": \"Echoes of the Past\",\n      \"author\": \"Amelia Hart\",\n      \"genre\": \"Romance\"\n    }\n  ]\n}\n\n```\n\n\n## Check whether conditions are satisfied {.smaller}\n\n::: {.cell execution_count=9}\n``` {.python .cell-code}\ntext_1 = f\"\"\"\nMaking a cup of tea is easy! First, you need to get some \\ \nwater boiling. While that's happening, \\ \ngrab a cup and put a tea bag in it. Once the water is \\ \nhot enough, just pour it over the tea bag. \\ \nLet it sit for a bit so the tea can steep. After a \\ \nfew minutes, take out the tea bag. If you \\ \nlike, you can add some sugar or milk to taste. \\ \nAnd that's it! You've got yourself a delicious \\ \ncup of tea to enjoy.\n\"\"\"\n```\n:::\n\n\n::: {.cell execution_count=10}\n```` {.python .cell-code}\nprompt = f\"\"\"\nYou will be provided with text delimited by triple backticks. \nIf it contains a sequence of instructions, \\ \nre-write those instructions in the following format:\n\nStep 1 - ...\nStep 2 - …\n…\nStep N - …\n\nIf the text does not contain a sequence of instructions, \\ \nthen simply write \\\"No steps provided.\\\"\n\n```{text_1}```\n\"\"\"\n````\n:::\n\n\n## Response {.smaller}\n\n::: {.cell execution_count=11}\n``` {.python .cell-code}\nresponse = get_completion(prompt)\n\nprint(\"Completion for Text 1:\")\nprint(response)\n```\n:::\n\n\n. . .\n\n```bash\nCompletion for Text 1:\nStep 1 - Get some water boiling.\nStep 2 - Grab a cup and put a tea bag in it.\nStep 3 - Pour the hot water over the tea bag.\nStep 4 - Let the tea steep for a bit.\nStep 5 - Take out the tea bag.\nStep 6 - Add sugar or milk to taste.\nStep 7 - Enjoy your cup of tea.\n```\n\n## Use \"few-shot\" prompting with examples \n\n- In few-shot prompting, examples are included directly in the prompt. \n- These examples serve as a reference or guide for the model to understand the task at hand.\n- Few-shot prompting can be an effective technique in prompt engineering, helping to guide the model's responses without the need for additional training data or fine-tuning.\n\n## Few-shot example {.smaller}\n\n::: {.cell execution_count=12}\n``` {.python .cell-code}\nprompt = f\"\"\"\nYour task is to answer in a consistent style.\n\n<child>: Teach me about patience.\n\n<grandparent>: The river that carves the deepest \\ \nvalley flows from a modest spring; the \\ \ngrandest symphony originates from a single note; \\ \nthe most intricate tapestry begins with a solitary thread.\n\n<child>: Teach me about resilience.\n\"\"\"\n```\n:::\n\n\n. . .\n\n::: {.cell execution_count=13}\n``` {.python .cell-code}\nresponse = get_completion(prompt)\nprint(response)\n```\n:::\n\n\n- *Output:* <grandparent>: Resilience is the unwavering strength that emerges from facing adversity. It is the ability to bounce back, to rise above challenges, and to persevere in the face of obstacles. Just like a tree that bends but does not break in a storm, resilience allows us to weather the storms of life and come out stronger on the other side.\n\n\n# Prompting Principle 2\n\nGive the model time to “think”\n\n## Specify the the steps and output {.smaller}\n\n::: {.cell execution_count=14}\n``` {.python .cell-code}\ntext = f\"\"\"\nIn a charming village, siblings Jack and Jill set out on \\ \na quest to fetch water from a hilltop \\ \nwell. As they climbed, singing joyfully, misfortune \\ \nstruck—Jack tripped on a stone and tumbled \\ \ndown the hill, with Jill following suit. \\ \nThough slightly battered, the pair returned home to \\ \ncomforting embraces. Despite the mishap, \\ \ntheir adventurous spirits remained undimmed, and they \\ \ncontinued exploring with delight.\n\"\"\"\n```\n:::\n\n\n. . .\n\n::: {.cell execution_count=15}\n``` {.python .cell-code}\nprompt_2 = f\"\"\"\nYour task is to perform the following actions: \n1 - Summarize the following text delimited by \n  <> with 1 sentence.\n2 - Translate the summary into German.\n3 - List each name in the German summary.\n4 - Output a json object that contains the \n  following keys: german_summary, num_names.\n\nUse the following format:\nText: <text to summarize>\nSummary: <summary>\nTranslation: <summary translation>\nNames: <list of names in German summary>\nOutput JSON: <json with summary and num_names>\n\nText: <{text}>\n\"\"\"\nresponse = get_completion(prompt_2)\nprint(\"\\nCompletion for prompt 2:\")\nprint(response)\n```\n:::\n\n\n## Output {.smaller}\n\n```bash\nCompletion for prompt 2:\nSummary: Jack and Jill go on a quest to fetch water from a hilltop well, but they both fall down the hill and return home slightly battered but with undimmed adventurous spirits.\n\nTranslation: Jack und Jill machen sich auf die Suche nach Wasser aus einem Brunnen auf einem Hügel, aber sie fallen beide den Hügel hinunter und kehren leicht lädiert, aber mit ungetrübtem Abenteuergeist nach Hause zurück.\n\nNames: Jack, Jill\n\nOutput JSON: {\"german_summary\": \"Jack und Jill machen sich auf die Suche nach Wasser aus einem Brunnen auf einem Hügel, aber sie fallen beide den Hügel hinunter und kehren leicht lädiert, aber mit ungetrübtem Abenteuergeist nach Hause zurück.\", \"num_names\": 2}\n```\n\n## Work on own solution {.smaller}\n\n- Instruct the model to work out its own solution before rushing to a conclusion\n\n. . .\n\n::: {.cell execution_count=16}\n``` {.python .cell-code}\nprompt = f\"\"\"\nYour task is to determine if the student's solution \\\nis correct or not.\nTo solve the problem do the following:\n- First, work out your own solution to the problem. \n- Then compare your solution to the student's solution \\ \nand evaluate if the student's solution is correct or not. \nDon't decide if the student's solution is correct until \nyou have done the problem yourself.\n\nUse the following format:\n\nQuestion:\n'''\nquestion here\n'''\n\nStudent's solution:\n'''\nstudent's solution here\n'''\n\nActual solution:\n'''\nsteps to work out the solution and your solution here\n'''\n\nIs the student's solution the same as actual solution \\\njust calculated:\n'''\nyes or no\n'''\n\nStudent grade:\n'''\ncorrect or incorrect\n'''\n\nQuestion:\n'''\nA bat and a ball cost $1.10 in total. \nThe bat costs $1.00 more than the ball. \nHow much does the ball cost?\n''' \nStudent's solution:\n'''\n1. The bat costs $1.00\n2. Therefore, the ball costs $0.10 \n'''\n\nActual solution:\n\"\"\"\nresponse = get_completion(prompt)\nprint(response)\n```\n:::\n\n\n## Output {.smaller}\n\n```bash\n'''\nLet's assume the cost of the ball is x dollars. \nAccording to the problem, the bat costs $1.00 more than the ball, so the cost of the bat is x + $1.00. \nThe total cost of the bat and the ball is $1.10, so we can write the equation: \nx + (x + $1.00) = $1.10 \nSimplifying the equation, we get: \n2x + $1.00 = $1.10 \nSubtracting $1.00 from both sides, we get: \n2x = $0.10 \nDividing both sides by 2, we get: \nx = $0.05 \nTherefore, the ball costs $0.05.\n'''\nIs the student's solution the same as actual solution just calculated:\n'''\nNo\n'''\nStudent grade:\n'''\nIncorrect\n'''\n```\n\n# Model Limitations: Hallucinations\n\nThe generation of factually incorrect or nonsensical information that wasn't present in the training data.\n\n## Causes\n\n- **Overgeneralization**: LLMs might overgeneralize from the patterns they have learned in the training data.\n\n- **Lack of Source of Truth**: Without a reliable source of truth during generation, LLMs can drift from accurate information.\n\n- **Insufficient Context**: Sometimes, the context provided to the model may not be sufficient for accurate generation.\n\n\n## Mitigation Strategies\n\n- **Data Augmentation**: Including a diverse range of data can help in reducing hallucinations.\n\n- **External Knowledge Bases**: Linking LLMs to external knowledge bases can provide a source of truth to verify generated information.\n\n- **User Feedback**: Incorporating user feedback can also help in identifying and reducing hallucinations.\n\n## Example {.smaller}\n\n- Boie is a real company, the product name is not real.\n\n::: {.cell execution_count=17}\n``` {.python .cell-code}\nprompt = f\"\"\"\nTell me about AeroGlide UltraSlim Smart Toothbrush by Boie\n\"\"\"\nresponse = get_completion(prompt)\nprint(response)\n```\n:::\n\n\n- *Output:* The AeroGlide UltraSlim Smart Toothbrush by Boie is a technologically advanced toothbrush designed to provide a superior brushing experience. Boie is a company known for its innovative oral care products, and the AeroGlide UltraSlim Smart Toothbrush is no exception. One of the standout features of this toothbrush is its ultra-slim design. The brush head is only 2mm thick, making it much thinner than traditional toothbrushes. This slim profile allows for better access to hard-to-reach areas of the mouth, ensuring a thorough and effective clean. The AeroGlide UltraSlim Smart Toothbrush also incorporates smart technology. It connects to a mobile app via Bluetooth, allowing users to track their brushing habits and receive personalized recommendations for improving their oral hygiene routine... \n\n\n# Acknowledgments\n\n*This tutorial is mainly based on an excellent course provided by Isa Fulford from OpenAI and Andrew Ng from DeepLearningAI as well as [OpenAI's GPT best practices](https://platform.openai.com/docs/guides/gpt-best-practices)*\n\n# What's next? {background-image=\"../images/logo.png\" background-opacity=\"0.5\"}\n\n**Congratulations! You have completed this tutorial** 👍\n\n**Next, you may want to go back to the [lab's website](https://kirenz.github.io/lab-prompt/)**\n\n",
    "supporting": [
      "guidelines_files"
    ],
    "filters": [],
    "includes": {}
  }
}