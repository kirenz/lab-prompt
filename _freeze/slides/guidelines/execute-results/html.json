{
  "hash": "52c958657362d99398969f54b7849777",
  "result": {
    "markdown": "---\ntitle: Prompt Engineering Guidelines\nlang: en\nsubtitle: Prompt Engineering 1\nauthor: Jan Kirenz\nexecute:\n  eval: false\n  echo: true\nhighlight-style: github\nformat:\n  revealjs: \n    toc: true\n    toc-depth: 1\n    embed-resources: false\n    theme: [dark, ../custom.scss]  \n    incremental: true\n    transition: slide\n    background-transition: fade\n    transition-speed: slow\n    code-copy: true\n    code-line-numbers: true\n    smaller: false\n    scrollable: true\n    slide-number: c\n    preview-links: auto\n    chalkboard: \n      buttons: false\n   #logo: images/logo.png\n    footer: Jan Kirenz\n---\n\n# Prompt Engineering Guidelines\n\nIn this tutorial, we'll practice two prompting principles and their related tactics in order to write effective prompts for large language models.\n\n## What is prompt engineering?\n\n- The inputs to LLMs are referred to as \"**prompts**\"\n\n- Designing a prompt is essentially how you “program” a LLM:\n  - with **instructions** \n  - or some **examples** of how to successfully complete a task\n\n- Prompt **engineering**\n  - methods to improve model reasoning \n  - reduce the likelihood of model hallucinations\n\n\n## Prompting in ChatGPT\n\n![](/images/prompt.png)\n\n## We use OpenAI's API {.smaller}\n\n![](/images/api.png)\n\n\n- The OpenAI API can be applied to virtually any task that requires understanding or generating natural language and code. \n\n- Can also be used to generate and edit images or convert speech into text.\n\n## Example prompt {.smaller}\n\n- Example prompt with a *system message* (helps set the behavior of the assistant)\n\n. . .\n\n::: {.cell execution_count=1}\n```` {.python .cell-code}\nprompt = f\"\"\"\nSummarize the text delimited by triple backticks \\ \ninto a single sentence and add a joke or playful comment\n\n```{text}```\n\"\"\"\n````\n:::\n\n\n- `f`: [Formatted strings](https://docs.python.org/3/tutorial/inputoutput.html) allow you to embed expressions inside string literals, using curly braces {}\n- `\"\"\"`: Triple double-quotes are used to denote a string that spans multiple lines. \n- `\\`: line breaks are used to make the text more readable\n- `{text}` is a placeholder for a variable text that will be placed into the string at that position. \n\n## Example text\n\n::: {.cell execution_count=2}\n``` {.python .cell-code}\ntext = f\"\"\"\nYou should express what you want a model to do by \\ \nproviding instructions that are as clear and \\ \nspecific as you can possibly make them. \\ \nThis will guide the model towards the desired output, \\ \nand reduce the chances of receiving irrelevant \\ \nor incorrect responses. Don't confuse writing a \\ \nclear prompt with writing a short prompt. \\ \nIn many cases, longer prompts provide more clarity \\ \nand context for the model, which can lead to \\ \nmore detailed and relevant outputs.\n\"\"\"\n```\n:::\n\n\n## Chat completion helper function {.smaller}\n\n::: {.cell execution_count=3}\n``` {.python .cell-code}\ndef get_completion(prompt, model=\"gpt-3.5-turbo\"): # <1>\n    messages = [{\"role\": \"user\", \"content\": prompt}] # <2>\n    response = openai.ChatCompletion.create( # <3>\n        model=model, # <4>\n        messages=messages, # <5>\n        temperature=0)   # <6>  \n    return response.choices[0].message[\"content\"] # <7>\n```\n:::\n\n\n1. Defines the function `get_completion` with two parameters\n2. Dictionary with two key-value pairs (role as `\"user\"`; content as `prompt`) \n3. Initiates an API call to OpenAI's [ChatCompletion](https://platform.openai.com/docs/guides/chat) method; result is stored in a variable named `response`.\n4. Specifies the model to be used (we always use `\"gpt-3.5-turbo\"`) \n5. Passes the `messages` list to the API\n6. The degree of randomness of the model's output (0 makes the model's output more focused and deterministic).\n7. Extracts and returns the content of the message. \n\n\n## What is a sytem message?\n\n- The *system message* is optional and helps set the behavior of the assistant.\n\n- You can modify the *personality* of the assistant or provide *specific instructions* about how it should behave\n  - You can use specific personas (e.g. write in the style of Socrates)\n  - If outputs are too simple, ask for expert-level writing.  \n  - If you dislike the format, demonstrate the format you’d like to see. \n\n## What is the temperature?\n\n- Lower values for temperature result in more consistent outputs\n\n- Higher values generate more diverse and creative results. \n\n- Select a temperature value based on the desired trade-off between coherence and creativity for your specific application.\n\n\n## What are tokens?\n\n- Language models read and write text in chunks called tokens. \n\n- In English, a token can be as short as one character or as long as one word (e.g., a or apple), \n\n- For example, the string \"ChatGPT is great!\" is encoded into six tokens: \n  - `[\"Chat\", \"G\", \"PT\", \" is\", \" great\", \"!\"]`.\n\n## Tokens\n\n![](/images/tokens.png)\n\n\n## Tokens and API calls\n\n- The total number of tokens in an API call affects:\n  - How much your API call costs, as you pay per token\n  - How long your API call takes, as writing more tokens takes more time\n  - Whether your API call works at all, as total tokens must be below the model’s maximum limit (4097 tokens for gpt-3.5-turbo)\n\n<!--\n\n## Function calling {.smaller}\n\n- Function calling allows you to more reliably get structured data back from the model\n\n- Examples: \n\n  - Create chatbots that answer questions by calling external APIs (e.g. like ChatGPT Plugins): e.g. define functions like send_email(to: string, body: string), or get_current_weather(location: string, unit: 'celsius' | 'fahrenheit')\n\n  - Convert natural language into API calls: e.g. convert \"Who are my top customers?\" to get_customers(min_revenue: int, created_before: string, limit: int) and call your internal API\n\n  - Extract structured data from text: e.g. define a function called extract_data(name: string, birthday: string), or sql_query(query: string)\n-->\n\n# Setup\n\n## API key and Python libaries\n\n::: {.cell execution_count=4}\n``` {.python .cell-code}\nimport openai\nimport os\n\nfrom dotenv import load_dotenv, find_dotenv\n_ = load_dotenv(find_dotenv())\n\nopenai.api_key = os.getenv('OPENAI_API_KEY')\n```\n:::\n\n\n## Helper function {.smaller}\n\n::: {.cell execution_count=5}\n``` {.python .cell-code}\ndef get_completion(prompt, model=\"gpt-3.5-turbo\"):\n    messages = [{\"role\": \"user\", \"content\": prompt}]\n    response = openai.ChatCompletion.create(\n        model=model,\n        messages=messages,\n        temperature=0, \n    )\n    return response.choices[0].message[\"content\"]\n\n```\n:::\n\n\n# Principle 1: Be clear and specific\n\nWrite clear and specific instructions\n\n\n## Use delimiters {.smaller}\n\n- Always use delimiters (like backticks) to clearly indicate distinct parts of the input\n\n. . .\n\n::: {.cell output-location='fragment' execution_count=6}\n```` {.python .cell-code}\ntext = f\"\"\"\nYou should express what you want a model to do by \\ \nproviding instructions that are as clear and \\ \nspecific as you can possibly make them. \\ \nThis will guide the model towards the desired output, \\ \nand reduce the chances of receiving irrelevant \\ \nor incorrect responses. Don't confuse writing a \\ \nclear prompt with writing a short prompt. \\ \nIn many cases, longer prompts provide more clarity \\ \nand context for the model, which can lead to \\ \nmore detailed and relevant outputs.\n\"\"\"\nprompt = f\"\"\"\nSummarize the text delimited by triple backticks \\ \ninto a single sentence and add a joke or playful comment\n```{text}```\n\"\"\"\nresponse = get_completion(prompt)\nprint(response)\n````\n:::\n\n\n- *Output:* \"To get the desired output from a model, it's important to give clear and specific instructions, and remember that longer prompts can actually be more helpful in providing context and clarity—just like how a detailed joke is often funnier!\"\n\n\n\n## Ask for structured output {.smaller}\n\n- Ask for a structured output (e.g. JSON, HTML, ...)\n\n. . .\n\n::: {.cell execution_count=7}\n``` {.python .cell-code}\nprompt = f\"\"\"\nGenerate a list of three made-up book titles along \\ \nwith their authors and genres. \nProvide them in JSON format with the following keys: \nbook_id, title, author, genre.\n\"\"\"\n```\n:::\n\n\n. . .\n\n::: {.cell execution_count=8}\n``` {.python .cell-code}\nresponse = get_completion(prompt)\nprint(response)\n```\n:::\n\n\n## Output {.smaller}\n\n```json\n{\n  \"books\": [\n    {\n      \"book_id\": 1,\n      \"title\": \"The Enigma of Elysium\",\n      \"author\": \"Evelyn Sinclair\",\n      \"genre\": \"Mystery\"\n    },\n    {\n      \"book_id\": 2,\n      \"title\": \"Whispers in the Wind\",\n      \"author\": \"Nathaniel Blackwood\",\n      \"genre\": \"Fantasy\"\n    },\n    {\n      \"book_id\": 3,\n      \"title\": \"Echoes of the Past\",\n      \"author\": \"Amelia Hart\",\n      \"genre\": \"Romance\"\n    }\n  ]\n}\n\n```\n\n\n## Check whether conditions are satisfied {.smaller}\n\n::: {.cell execution_count=9}\n``` {.python .cell-code}\ntext_1 = f\"\"\"\nBegin with a clear understanding of the desired outcome from the prompt, including the \\ \nkind of information and format you seek in the response. Familiarize yourself with the \\ \ncapabilities and limitations of the model you're working with, ensuring you know its  \\ \nstrengths and weaknesses in generating text. Draft a preliminary version of your prompt, \\ \nkeeping it concise yet detailed enough to guide the model towards the desired outcome. \\ \nTest the preliminary prompt with the model, analyzing the generated responses for \\ \naccuracy, relevance, and completeness. Refine the prompt based on the feedback from the \\ \ninitial testing, adjusting the language, structure, or additional details as necessary. \\ \nPerform multiple rounds of testing and refinement, continually honing the prompt for \\ \nbetter results. Document the final version of the prompt and any notable observations from \\ \nthe testing process for future reference and learning.\n\"\"\"\n```\n:::\n\n\n::: {.cell execution_count=10}\n```` {.python .cell-code}\nprompt = f\"\"\"\nYou will be provided with text delimited by triple backticks. \nIf it contains a sequence of instructions, \\ \nre-write those instructions in the following format:\n\nStep 1 - ...\nStep 2 - …\n…\nStep N - …\n\n\n\nIf the text does not contain a sequence of instructions, \\ \nthen simply write \\\"No steps provided.\\\"\n\n```{text_1}```\n\"\"\"\n````\n:::\n\n\n## Response {.smaller}\n\n::: {.cell execution_count=11}\n``` {.python .cell-code}\nresponse = get_completion(prompt)\n\nprint(\"Completion for Text 1:\")\nprint(response)\n```\n:::\n\n\n. . .\n\n```markdown\nCompletion for Text 1:  \nStep 1 - Begin with a clear understanding of the desired outcome from the prompt, including the kind of information and format you seek in the response.\nStep 2 - Familiarize yourself with the capabilities and limitations of the model you're working with, ensuring you know its strengths and weaknesses in generating text.\nStep 3 - Draft a preliminary version of your prompt, keeping it concise yet detailed enough to guide the model towards the desired outcome.\nStep 4 - Test the preliminary prompt with the model, analyzing the generated responses for accuracy, relevance, and completeness.\nStep 5 - Refine the prompt based on the feedback from the initial testing, adjusting the language, structure, or additional details as necessary.\nStep 6 - Perform multiple rounds of testing and refinement, continually honing the prompt for better results.\nStep 7 - Document the final version of the prompt and any notable observations from the testing process for future reference and learning.\n```\n\n## Use \"few-shot\" prompting with examples \n\n- In few-shot prompting, examples are included directly in the prompt. \n- These examples serve as a reference or guide for the model to understand the task at hand.\n- Few-shot prompting can be an effective technique in prompt engineering, helping to guide the model's responses without the need for additional training data or fine-tuning.\n\n## Few-shot example {.smaller}\n\n::: {.cell execution_count=12}\n``` {.python .cell-code}\nprompt = f\"\"\"\nYour task is to answer in a consistent style.\n\n<child>: Teach me about patience.\n\n<grandparent>: The river that carves the deepest \\ \nvalley flows from a modest spring; the \\ \ngrandest symphony originates from a single note; \\ \nthe most intricate tapestry begins with a solitary thread.\n\n<child>: Teach me about resilience.\n\"\"\"\n```\n:::\n\n\n. . .\n\n::: {.cell execution_count=13}\n``` {.python .cell-code}\nresponse = get_completion(prompt)\nprint(response)\n```\n:::\n\n\n- *Output:* \\<grandparent\\>: Resilience is the unwavering strength that emerges from facing adversity. It is the ability to bounce back, to rise above challenges, and to persevere in the face of obstacles. Just like a tree that bends but does not break in a storm, resilience allows us to weather the storms of life and come out stronger on the other side.\n\n\n# Principle 2: Time to think\n\nGive the model time to “think”\n\n## Specify the the steps and output {.smaller}\n\n::: {.cell execution_count=14}\n``` {.python .cell-code}\ntext = f\"\"\"\nPrompt engineering is a pivotal aspect of harnessing the full \\ \npotential of language models such as OpenAI's ChatGPT. It serves \\ \nas a conduit between human intent and machine comprehension, \\ \nfacilitating a clearer transmission of the task or information desired. \\ \nBy meticulously crafting prompts, individuals can steer ChatGPT towards  \\ \ndelivering more precise, pertinent, and beneficial responses. The iterative \\ \nprocess of refining prompts in prompt engineering not only augments the \\ \ninteraction with ChatGPT but also furthers the overarching objective of \\ \nmaking AI more accessible and in tune with human requirements. Furthermore, \\ \nit furnishes invaluable insights into ChatGPT's behavior, thereby aiding \\ \nthe continuous effort to enhance and fine-tune AI systems developed by OpenAI.\n\"\"\"\n```\n:::\n\n\n. . .\n\n::: {.cell execution_count=15}\n``` {.python .cell-code}\nprompt_2 = f\"\"\"\nYour task is to perform the following actions: \n1 - Summarize the following text delimited by \n  <> with 1 sentence.\n2 - Translate the summary into German.\n3 - List each name in the German summary.\n4 - Output a json object that contains the \n  following keys: german_summary, num_names.\n\nUse the following format:\nText: <text to summarize>\nSummary: <summary>\nTranslation: <summary translation>\nNames: <list of names in German summary>\nOutput JSON: <json with summary and num_names>\n\nText: <{text}>\n\"\"\"\nresponse = get_completion(prompt_2)\nprint(\"\\nCompletion for prompt 2:\")\nprint(response)\n```\n:::\n\n\n## Output {.smaller}\n\nCompletion for prompt 2:\nSummary: Prompt engineering is crucial for maximizing the potential of language models like OpenAI's ChatGPT by improving the clarity and precision of responses, making AI more accessible and aligned with human needs, and providing valuable insights for enhancing and fine-tuning AI systems.\n\nTranslation: Die Gestaltung von Anweisungen ist entscheidend, um das Potenzial von Sprachmodellen wie OpenAI's ChatGPT optimal zu nutzen, indem die Klarheit und Präzision der Antworten verbessert wird, was die Zugänglichkeit von KI erhöht und auf die Bedürfnisse der Menschen abstimmt, sowie wertvolle Einblicke für die Verbesserung und Feinabstimmung von KI-Systemen liefert.\n\nNames: ChatGPT, OpenAI\n\nOutput JSON: \n{\n  \"german_summary\": \"Die Gestaltung von Anweisungen ist entscheidend, um das Potenzial von Sprachmodellen wie OpenAI's ChatGPT optimal zu nutzen, indem die Klarheit und Präzision der Antworten verbessert wird, was die Zugänglichkeit von KI erhöht und auf die Bedürfnisse der Menschen abstimmt, sowie wertvolle Einblicke für die Verbesserung und Feinabstimmung von KI-Systemen liefert.\",\n  \"num_names\": 2\n}\n\n\n## Work on own solution {.smaller}\n\n- Instruct the model to work out its own solution before rushing to a conclusion\n\n. . .\n\n::: {.cell execution_count=16}\n``` {.python .cell-code}\nprompt = f\"\"\"\nYour task is to determine if the student's solution \\\nis correct or not.\nTo solve the problem do the following:\n- First, work out your own solution to the problem. \n- Then compare your solution to the student's solution \\ \nand evaluate if the student's solution is correct or not. \nDon't decide if the student's solution is correct until \nyou have done the problem yourself.\n\nUse the following format:\n\nQuestion:\n'''\nquestion here\n'''\n\nStudent's solution:\n'''\nstudent's solution here\n'''\n\nActual solution:\n'''\nsteps to work out the solution and your solution here\n'''\n\nIs the student's solution the same as actual solution \\\njust calculated:\n'''\nyes or no\n'''\n\nStudent grade:\n'''\ncorrect or incorrect\n'''\n\nQuestion:\n'''\nA bat and a ball cost $1.10 in total. \nThe bat costs $1.00 more than the ball. \nHow much does the ball cost?\n''' \nStudent's solution:\n'''\n1. The bat costs $1.00\n2. Therefore, the ball costs $0.10 \n'''\n\nActual solution:\n\"\"\"\nresponse = get_completion(prompt)\nprint(response)\n```\n:::\n\n\n## Output {.smaller}\n\nLet's assume the cost of the ball is x dollars. \n\nAccording to the problem, the bat costs $1.00 more than the ball, so the cost of the bat is x + $1.00. \nThe total cost of the bat and the ball is $1.10, so we can write the equation: \n\nx + (x + $1.00) = $1.10  \nSimplifying the equation, we get:  \n2x + $1.00 = $1.10  \nSubtracting $1.00 from both sides, we get:  \n2x = $0.10  \nDividing both sides by 2, we get:  \nx = $0.05  \nTherefore, the ball costs $0.05. \n'''  \nIs the student's solution the same as actual solution just calculated:  \n'''  \nNo  \n'''  \nStudent grade:  \n'''  \nIncorrect  \n'''  \n\n\n# Model Limitations: Hallucinations\n\nThe generation of factually incorrect or nonsensical information that wasn't present in the training data.\n\n## Causes\n\n- **Overgeneralization**: LLMs might overgeneralize from the patterns they have learned in the training data.\n\n- **Lack of Source of Truth**: Without a reliable source of truth during generation, LLMs can drift from accurate information.\n\n- **Insufficient Context**: Sometimes, the context provided to the model may not be sufficient for accurate generation.\n\n\n## Mitigation Strategies\n\n- **Data Augmentation**: Including a diverse range of data can help in reducing hallucinations.\n\n- **External Knowledge Bases**: Linking LLMs to external knowledge bases can provide a source of truth to verify generated information.\n\n- **User Feedback**: Incorporating user feedback can also help in identifying and reducing hallucinations.\n\n## Example {.smaller}\n\n- Boie is a real company, the product name is not real.\n\n::: {.cell execution_count=17}\n``` {.python .cell-code}\nprompt = f\"\"\"\nTell me about AeroGlide UltraSlim Smart Toothbrush by Boie. Use about 50 words.\n\"\"\"\nresponse = get_completion(prompt)\nprint(response)\n```\n:::\n\n\n- *Output:* The AeroGlide UltraSlim Smart Toothbrush by Boie is a technologically advanced toothbrush designed to provide a superior brushing experience. Boie is a company known for its innovative oral care products, and the AeroGlide UltraSlim Smart Toothbrush is no exception. One of the standout features of this toothbrush is its ultra-slim design. The brush head is only 2mm thick, making it much thinner than traditional toothbrushes. This slim profile allows for better access to hard-to-reach areas of the mouth, ensuring a thorough and effective clean. The AeroGlide UltraSlim Smart Toothbrush also incorporates smart technology. It connects to a mobile app via Bluetooth, allowing users to track their brushing habits and receive personalized recommendations for improving their oral hygiene routine... \n\n\n# Acknowledgments\n\n*This tutorial is mainly based on an excellent course provided by Isa Fulford from OpenAI and Andrew Ng from DeepLearningAI as well as [OpenAI's GPT best practices](https://platform.openai.com/docs/guides/gpt-best-practices)*\n\n# What's next? {background-image=\"../images/logo.png\" background-opacity=\"0.5\"}\n\n**Congratulations! You have completed this tutorial** 👍\n\n**Next, you may want to go back to the [lab's website](https://kirenz.github.io/lab-prompt/)**\n\n",
    "supporting": [
      "guidelines_files"
    ],
    "filters": [],
    "includes": {}
  }
}